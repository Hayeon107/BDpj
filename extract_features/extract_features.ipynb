{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "453fd147",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting librosa\n",
      "  Downloading librosa-0.10.1-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting audioread>=2.1.9 (from librosa)\n",
      "  Downloading audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in c:\\users\\lockd\\anaconda3\\envs\\pytest\\lib\\site-packages (from librosa) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\lockd\\anaconda3\\envs\\pytest\\lib\\site-packages (from librosa) (1.10.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\lockd\\anaconda3\\envs\\pytest\\lib\\site-packages (from librosa) (1.2.1)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\lockd\\anaconda3\\envs\\pytest\\lib\\site-packages (from librosa) (1.2.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\lockd\\anaconda3\\envs\\pytest\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Collecting numba>=0.51.0 (from librosa)\n",
      "  Downloading numba-0.58.1-cp310-cp310-win_amd64.whl.metadata (2.8 kB)\n",
      "Collecting soundfile>=0.12.1 (from librosa)\n",
      "  Downloading soundfile-0.12.1-py2.py3-none-win_amd64.whl (1.0 MB)\n",
      "     ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "     --------------- ------------------------ 0.4/1.0 MB 12.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.0/1.0 MB 12.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.0/1.0 MB 12.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pooch>=1.0 in c:\\users\\lockd\\anaconda3\\envs\\pytest\\lib\\site-packages (from librosa) (1.7.0)\n",
      "Collecting soxr>=0.3.2 (from librosa)\n",
      "  Downloading soxr-0.3.7-cp310-cp310-win_amd64.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\lockd\\anaconda3\\envs\\pytest\\lib\\site-packages (from librosa) (4.4.0)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in c:\\users\\lockd\\appdata\\roaming\\python\\python310\\site-packages (from librosa) (0.3)\n",
      "Collecting msgpack>=1.0 (from librosa)\n",
      "  Downloading msgpack-1.0.7-cp310-cp310-win_amd64.whl.metadata (9.4 kB)\n",
      "Collecting llvmlite<0.42,>=0.41.0dev0 (from numba>=0.51.0->librosa)\n",
      "  Downloading llvmlite-0.41.1-cp310-cp310-win_amd64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\lockd\\anaconda3\\envs\\pytest\\lib\\site-packages (from pooch>=1.0->librosa) (2.5.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lockd\\anaconda3\\envs\\pytest\\lib\\site-packages (from pooch>=1.0->librosa) (23.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\lockd\\anaconda3\\envs\\pytest\\lib\\site-packages (from pooch>=1.0->librosa) (2.31.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\lockd\\anaconda3\\envs\\pytest\\lib\\site-packages (from scikit-learn>=0.20.0->librosa) (3.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\lockd\\anaconda3\\envs\\pytest\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\lockd\\anaconda3\\envs\\pytest\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lockd\\anaconda3\\envs\\pytest\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lockd\\anaconda3\\envs\\pytest\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lockd\\anaconda3\\envs\\pytest\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lockd\\anaconda3\\envs\\pytest\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2023.7.22)\n",
      "Downloading librosa-0.10.1-py3-none-any.whl (253 kB)\n",
      "   ---------------------------------------- 0.0/253.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 253.7/253.7 kB 16.2 MB/s eta 0:00:00\n",
      "Downloading audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Downloading msgpack-1.0.7-cp310-cp310-win_amd64.whl (222 kB)\n",
      "   ---------------------------------------- 0.0/222.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 222.8/222.8 kB 13.3 MB/s eta 0:00:00\n",
      "Downloading numba-0.58.1-cp310-cp310-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.7/2.6 MB 20.8 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.4/2.6 MB 17.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.2/2.6 MB 19.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.6/2.6 MB 18.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.6/2.6 MB 16.5 MB/s eta 0:00:00\n",
      "Downloading soxr-0.3.7-cp310-cp310-win_amd64.whl (184 kB)\n",
      "   ---------------------------------------- 0.0/184.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 184.6/184.6 kB ? eta 0:00:00\n",
      "Downloading llvmlite-0.41.1-cp310-cp310-win_amd64.whl (28.1 MB)\n",
      "   ---------------------------------------- 0.0/28.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.0/28.1 MB 32.0 MB/s eta 0:00:01\n",
      "   -- ------------------------------------- 2.0/28.1 MB 25.1 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 2.8/28.1 MB 24.9 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 3.5/28.1 MB 22.6 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 4.4/28.1 MB 23.5 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 5.3/28.1 MB 22.5 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 5.8/28.1 MB 20.7 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 6.8/28.1 MB 21.7 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 7.4/28.1 MB 20.6 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 8.1/28.1 MB 20.0 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 8.9/28.1 MB 20.3 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 9.6/28.1 MB 19.8 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 9.8/28.1 MB 19.6 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 10.2/28.1 MB 18.0 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 11.3/28.1 MB 18.2 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 11.9/28.1 MB 17.7 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 12.7/28.1 MB 17.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 13.5/28.1 MB 17.7 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 14.2/28.1 MB 17.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 15.0/28.1 MB 17.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 16.0/28.1 MB 17.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 16.9/28.1 MB 17.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 17.9/28.1 MB 18.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 18.8/28.1 MB 18.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 19.7/28.1 MB 19.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 20.8/28.1 MB 21.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 21.8/28.1 MB 21.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 22.7/28.1 MB 21.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 23.6/28.1 MB 22.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 24.7/28.1 MB 23.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 25.4/28.1 MB 24.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 26.2/28.1 MB 22.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 27.1/28.1 MB 22.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  28.1/28.1 MB 22.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  28.1/28.1 MB 22.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 28.1/28.1 MB 19.8 MB/s eta 0:00:00\n",
      "Installing collected packages: soxr, msgpack, llvmlite, audioread, soundfile, numba, librosa\n",
      "Successfully installed audioread-3.0.1 librosa-0.10.1 llvmlite-0.41.1 msgpack-1.0.7 numba-0.58.1 soundfile-0.12.1 soxr-0.3.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\lockd\\anaconda3\\envs\\pytest\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\lockd\\anaconda3\\envs\\pytest\\lib\\site-packages)\n",
      "WARNING: Error parsing requirements for torch: [Errno 2] No such file or directory: 'c:\\\\users\\\\lockd\\\\anaconda3\\\\envs\\\\pytest\\\\lib\\\\site-packages\\\\torch-2.0.0.dist-info\\\\METADATA'\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\lockd\\anaconda3\\envs\\pytest\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\lockd\\anaconda3\\envs\\pytest\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15ae2589",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lockd\\anaconda3\\envs\\pyTest\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\lockd\\anaconda3\\envs\\pyTest\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "C:\\Users\\lockd\\anaconda3\\envs\\pyTest\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.23-246-g3d31191b-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a144295c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4 = pd.read_csv(\"C:/Users/lockd/data/BD/감정 분류를 위한 대화 음성 데이터셋/most_common/4차년도_most_common (1).csv\")\n",
    "df_5 = pd.read_csv(\"C:/Users/lockd/data/BD/감정 분류를 위한 대화 음성 데이터셋/most_common/5차년도_most_common.csv\")\n",
    "df_5_2 = pd.read_csv(\"C:/Users/lockd/data/BD/감정 분류를 위한 대화 음성 데이터셋/most_common/5차년도_2차_most_common.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79f7f814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counterimport numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Bidirectional\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ac348ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drive 경로\n",
    "drive_path = \"C:/Users/lockd/data/BD/감정 분류를 위한 대화 음성 데이터셋\"\n",
    "\n",
    "# dataset 경로\n",
    "dataset_path_4 = f\"{drive_path}/4차년도/\"\n",
    "dataset_path_5 = f\"{drive_path}/5차년도/5차_wav/\"\n",
    "dataset_path_5_2 = f\"{drive_path}/5차년도_2차/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "151c2037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(df):\n",
    "    mfcc_len_list=[]\n",
    "    mfcc_data = []\n",
    "    for name in tqdm(df['wav_id']):\n",
    "        path = None\n",
    "        path = f\"{dataset_path_4}{name}.wav\"\n",
    "        if(os.path.isfile(path)):\n",
    "            y, sr = librosa.load(path, sr=48000)\n",
    "            mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13, hop_length=int(sr*0.01), n_fft=int(sr*0.02))\n",
    "            mfcc_data.append(mfccs.T)\n",
    "            mfcc_len_list.append(len(mfccs.T))\n",
    "        else:\n",
    "            # 빈 배열 반환\n",
    "            print(f\"Warning: File not found for {name}\")\n",
    "            #return np.array([])\n",
    "    return mfcc_data, mfcc_len_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "45a6d86e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "123c092f4a2d43f18c81748a6fab1c14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14606 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: File not found for 5e2979c25807b852d9e018d5\n",
      "Warning: File not found for 5e298b9f5807b852d9e01a0f\n",
      "Warning: File not found for 5e298bc45807b852d9e01a10\n",
      "Warning: File not found for 5e298bdc5807b852d9e01a11\n",
      "Warning: File not found for 5e298c085807b852d9e01a12\n",
      "Warning: File not found for 5e2ad4145807b852d9e020d9\n",
      "Warning: File not found for 5e2ad43e5807b852d9e020dc\n",
      "Warning: File not found for 5e2998b85807b852d9e01b02\n",
      "Warning: File not found for 5e3161c65807b852d9e032af\n",
      "Warning: File not found for 5e31622f5807b852d9e032ba\n",
      "Warning: File not found for 5e32924e5807b852d9e03894\n",
      "Warning: File not found for 5e3292655807b852d9e03896\n",
      "Warning: File not found for 5e3292825807b852d9e0389a\n",
      "Warning: File not found for 5e315dca5807b852d9e03275\n",
      "Warning: File not found for 5e33a9d35807b852d9e050f4\n",
      "Warning: File not found for 5e33638b5807b852d9e04aeb\n"
     ]
    }
   ],
   "source": [
    "mfcc_data_4, mfcc_len_list_4 = extract_features(df_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9a653424",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ndarray로 변환\n",
    "df_4_features_np = np.array(mfcc_data_4, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2e4899db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5,5_2추출 함수\n",
    "def extract_features_re(df,data_path):\n",
    "    mfcc_len_list=[]\n",
    "    mfcc_data = []\n",
    "    for name in tqdm(df['wav_id']):\n",
    "        path = None\n",
    "        path = f\"{data_path}{name}.wav\"\n",
    "        if(os.path.isfile(path)):\n",
    "            y, sr = librosa.load(path, sr=48000)\n",
    "            mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13, hop_length=int(sr*0.01), n_fft=int(sr*0.02))\n",
    "            mfcc_data.append(mfccs.T)\n",
    "            mfcc_len_list.append(len(mfccs.T))\n",
    "        else:\n",
    "            # 빈 배열 반환\n",
    "            print(f\"Warning: File not found for {name}\")\n",
    "            #return np.array([])\n",
    "\n",
    "    return mfcc_data, mfcc_len_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "67ab724c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16273f6e19e749feb12e1c5fc335a256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10011 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#5차 오디오 특성 추출\n",
    "mfcc_data_5, mfcc_len_list_5=extract_features_re(df_5,dataset_path_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cda8c43b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a659090a1e14d98ab878e6f7b939c70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19374 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#5차 2차 오디오 특성추출\n",
    "mfcc_data_5_2, mfcc_len_list_5_2 = extract_features_re(df_5_2,dataset_path_5_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "aef8735b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ndarray변환\n",
    "mfcc_data_5 = np.array(mfcc_data_5, dtype=object)\n",
    "mfcc_data_5_2 = np.array(mfcc_data_5_2, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4a015d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#npy로 저장\n",
    "np.save(\"C:/Users/lockd/data/BD/감정 분류를 위한 대화 음성 데이터셋/data_5_features\", mfcc_data_5)\n",
    "np.save(\"C:/Users/lockd/data/BD/감정 분류를 위한 대화 음성 데이터셋/data_4_features_np\", df_4_features_np)\n",
    "np.save(\"C:/Users/lockd/data/BD/감정 분류를 위한 대화 음성 데이터셋/data_5_2_features_np\", mfcc_data_5_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bac4f0a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2505"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(mfcc_len_list_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "35b971f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5897"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(mfcc_len_list_5_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a0838ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4412"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(mfcc_len_list_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "65de2407",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ndarray 병합\n",
    "merged_array = np.concatenate((df_4_features_np, mfcc_data_5,mfcc_data_5_2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c9580780",
   "metadata": {},
   "outputs": [],
   "source": [
    "#병합한 ndarray 저장\n",
    "np.save(\"C:/Users/lockd/data/BD/감정 분류를 위한 대화 음성 데이터셋/total_features\", merged_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f8a64b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#병합한 ndarray 불러오기\n",
    "total_features = np.load(\"C:/Users/lockd/data/BD/감정 분류를 위한 대화 음성 데이터셋/total_features.npy\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b2bf2465",
   "metadata": {},
   "outputs": [],
   "source": [
    "#패딩. 위의 list에서 최댓값이 5897 이었으므로 이를 기준으로 한다\n",
    "df_features_padded = pad_sequences(total_features,maxlen=5897, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b4ffde62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43975"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#총 특성 데이터 43975개\n",
    "len(df_features_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8723b723",
   "metadata": {},
   "outputs": [],
   "source": [
    "#특성데이터 패딩한거 저장\n",
    "np.save(\"C:/Users/lockd/data/BD/감정 분류를 위한 대화 음성 데이터셋/total_features_padded\", df_features_padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2847f02",
   "metadata": {},
   "source": [
    "### emotion 레이블 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "78055973",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4차시의 missing 데이터 제거\n",
    "missing_wav_id = [\"5e2979c25807b852d9e018d5\",\"5e298b9f5807b852d9e01a0f\",\"5e298bc45807b852d9e01a10\",\"5e298bdc5807b852d9e01a11\",\"5e298c085807b852d9e01a12\",\"5e2ad4145807b852d9e020d9\",\"5e2ad43e5807b852d9e020dc\",\"5e2998b85807b852d9e01b02\",\"5e3161c65807b852d9e032af\",\"5e31622f5807b852d9e032ba\",\"5e32924e5807b852d9e03894\",\"5e3292655807b852d9e03896\",\"5e3292825807b852d9e0389a\",\"5e315dca5807b852d9e03275\",\"5e33a9d35807b852d9e050f4\",\"5e33638b5807b852d9e04aeb\"]\n",
    "# csv에만 있는데이터를 제거한다\n",
    "for i in missing_wav_id:\n",
    "    df_4.drop(df_4[(df_4['wav_id']==i)].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b0f74b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_5와 df_5_2는 상관없으니까 그냥 병합\n",
    "y_total = pd.concat([df_4[\"emotion\"], df_5[\"emotion\"],df_5_2[\"emotion\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "04fb3f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#다 합친 전체 데이터 프레임 저장\n",
    "df_total = pd.concat([df_4,df_5,df_5_2])\n",
    "df_total.to_csv(\"df_total.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bbe53921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43975"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#레이블 길이가 특성 데이터 길이와 같은것을 확인\n",
    "len(y_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "85f569c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#레이블 원핫인코딩\n",
    "y_one_hot = pd.get_dummies(y_total).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e8adb0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#원핫 인코딩 레이블 저장\n",
    "np.save(\"C:/Users/lockd/data/BD/감정 분류를 위한 대화 음성 데이터셋/total_labels\", y_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f5100234",
   "metadata": {},
   "outputs": [],
   "source": [
    "#레이블 원핫인코딩 후 저장하기\n",
    "y_one_hot_4 = pd.get_dummies(df_4[\"emotion\"]).values\n",
    "y_one_hot_5 = pd.get_dummies(df_5[\"emotion\"]).values\n",
    "y_one_hot_5_2 = pd.get_dummies(df_5_2[\"emotion\"]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0573039e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"C:/Users/lockd/data/BD/감정 분류를 위한 대화 음성 데이터셋/df_4_labels\", y_one_hot_4)\n",
    "np.save(\"C:/Users/lockd/data/BD/감정 분류를 위한 대화 음성 데이터셋/df_5_labels\", y_one_hot_5)\n",
    "np.save(\"C:/Users/lockd/data/BD/감정 분류를 위한 대화 음성 데이터셋/df_5_2_labels\", y_one_hot_5_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55cca51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
